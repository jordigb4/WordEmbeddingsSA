{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-family:Courier New; color:#CCCCCC\">**Text Similarity**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-family:Courier New; color:#336666\">**Load Data and Imports**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "%pip install datasets\n",
    "%pip install \n",
    "%pip install -U spacy\n",
    "!python3 -m spacy download ca_core_news_md\n",
    "!python3 -m spacy download ca_core_news_trf\n",
    "%pip install spacy-transformers\n",
    "%pip install scipy\n",
    "%pip install tensorflow\n",
    "%pip install transformers\n",
    "%pip install pandas\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requisites\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from gensim.models import KeyedVectors,TfidfModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.corpora import Dictionary\n",
    "import numpy as np\n",
    "import spacy\n",
    "import spacy_transformers\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from typing import Tuple, List\n",
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from gensim.matutils import corpus2csc\n",
    "import scipy\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\load.py:1486: FutureWarning: The repository for projecte-aina/sts-ca contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/projecte-aina/sts-ca\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# DATA\n",
    "dataset = load_dataset(\"projecte-aina/sts-ca\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-family:Courier New; color:#336666\">**Preprocessing and dataframes creation**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to preprocess the data in incontextual embedding models, we will stablish stopword treatment and simple_preprocess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS_CAT ={\n",
    "    \"a\", \"abans\", \"algun\", \"alguna\", \"algunes\", \"alguns\", \"altre\", \"amb\", \"ambdós\", \"anar\", \n",
    "    \"ans\", \"aquell\", \"aquelles\", \"aquells\", \"aquí\", \"bastant\", \"bé\", \"cada\", \"com\", \n",
    "    \"consegueixo\", \"conseguim\", \"conseguir\", \"consigueix\", \"consigueixen\", \"consigueixes\", \n",
    "    \"dalt\", \"de\", \"des\", \"dins\", \"el\", \"elles\", \"ells\", \"els\", \"en\", \"ens\", \"entre\", \n",
    "    \"era\", \"erem\", \"eren\", \"eres\", \"es\", \"és\", \"éssent\", \"està\", \"estan\", \"estat\", \n",
    "    \"estava\", \"estem\", \"esteu\", \"estic\", \"ets\", \"fa\", \"faig\", \"fan\", \"fas\", \"fem\", \n",
    "    \"fer\", \"feu\", \"fi\", \"haver\", \"i\", \"inclòs\", \"jo\", \"la\", \"les\", \"llarg\", \"llavors\", \n",
    "    \"mentre\", \"meu\", \"mode\", \"molt\", \"molts\", \"nosaltres\", \"o\", \"on\", \"per\", \"però\", \n",
    "    \"perquè\", \"podem\", \"poden\", \"poder\", \"podeu\", \"potser\", \"primer\", \"puc\", \"quan\", \n",
    "    \"quant\", \"que\", \"què\", \"qui\", \"sabem\", \"saben\", \"saber\", \"sabeu\", \"sap\", \"saps\", \n",
    "    \"sense\", \"ser\", \"seu\", \"seus\", \"si\", \"soc\", \"solament\", \"sols\", \"som\", \"sota\", \n",
    "    \"també\", \"te\", \"tene\", \"tenim\", \"tenir\", \"teniu\", \"teu\", \"tinc\", \"tot\", \"últim\", \n",
    "    \"un\", \"una\", \"unes\", \"uns\", \"ús\", \"va\", \"vaig\", \"van\", \"vosaltres\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing\n",
    "def preprocess(sentence: str, stop:bool = True) -> List[str]:\n",
    "    preprocessed = simple_preprocess(sentence)\n",
    "    if stop: preprocessed = [token for token in preprocessed if token not in STOPWORDS_CAT]\n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"font-family:Courier New; color:#336633\">**Dataset format creation**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family:Courier New; color:#994C00\">**Count-Vectorizer/TF-IDF**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pairs = [(e[\"sentence1\"], e[\"sentence2\"], e[\"label\"], ) for e in dataset[\"train\"].to_list()]\n",
    "input_pairs_val = [(e[\"sentence1\"], e[\"sentence2\"], e[\"label\"], ) for e in dataset[\"validation\"].to_list()]\n",
    "input_pairs_test = [(e[\"sentence1\"], e[\"sentence2\"], e[\"label\"], ) for e in dataset[\"test\"].to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_input_pairs = input_pairs + input_pairs_val + input_pairs_test\n",
    "# Preprocessament de les frases i creació dels diccionaris\n",
    "\n",
    "# Frases per a models contextuals, amb stopwords\n",
    "sentences_1 = [preprocess(sentence_1,stop = False) for sentence_1, _, _ in all_input_pairs]\n",
    "sentences_2 = [preprocess(sentence_2,stop = False) for _, sentence_2, _ in all_input_pairs]\n",
    "\n",
    "# Frases per a models no contextuals, sense stopwords\n",
    "sentences_1_preproc = [preprocess(sentence_1) for sentence_1, _, _ in all_input_pairs]\n",
    "sentences_2_preproc = [preprocess(sentence_2) for _, sentence_2, _ in all_input_pairs]\n",
    "\n",
    "sentence_pairs_preproc = list(zip(sentences_1_preproc, sentences_2_preproc))\n",
    "sentence_pairs = list(zip(sentences_1, sentences_2))\n",
    "\n",
    "# Versió aplanada de les frases\n",
    "sentences_pairs_flattened_preproc = sentences_1_preproc + sentences_2_preproc\n",
    "sentences_pairs_flattened = sentences_1 + sentences_2\n",
    "\n",
    "dict_preproc = Dictionary(sentences_pairs_flattened_preproc)\n",
    "dict_preproc_complete = Dictionary(sentences_pairs_flattened)\n",
    "\n",
    "# Filtrem tamany de diccionari per les variants estàndard de TF-IDF i BOW\n",
    "\n",
    "dict_preproc.filter_extremes(keep_n=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de pesos TF-IDF per les frases preprocessades\n",
    "corpus = [dict_preproc.doc2bow(sent) for sent in sentences_pairs_flattened_preproc]\n",
    "corpus_complete = [dict_preproc_complete.doc2bow(sent) for sent in sentences_pairs_flattened_preproc]\n",
    "model_tfidf = TfidfModel(corpus)\n",
    "model_tfidf_complete = TfidfModel(corpus_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get count vector from dictionary\n",
    "def map_to_bow(sentence: List[str], dictionary: Dictionary) -> np.ndarray:\n",
    "    vec = np.zeros(len(dictionary))   \n",
    "    bow = dictionary.doc2bow(sentence)\n",
    "    for token_id, count in bow:\n",
    "        vec[token_id] = count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_tf_idf(sentence: List[str], dictionary: Dictionary, tfidf: TfidfModel) -> np.ndarray:\n",
    "    vec = np.zeros(len(dictionary))   \n",
    "    bow = dictionary.doc2bow(sentence)   \n",
    "    for token_id, value in tfidf[bow]:\n",
    "        vec[token_id] = value\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process all pairs\n",
    "def bow_pairs(sentence_pairs: List[Tuple[str, str, float]], dictionary: Dictionary = None,tf:bool = False,model_tfidf:TfidfModel = None) -> List[Tuple[Tuple[np.ndarray, np.ndarray], float]]:\n",
    "\n",
    "    pair_vectors = []\n",
    "    for (s1,s2,sim) in sentence_pairs:\n",
    "        \n",
    "        s1_preproc = preprocess(s1)\n",
    "        s2_preproc = preprocess(s2)\n",
    "        \n",
    "        if tf == False:\n",
    "            vectors_1 = map_to_bow(s1_preproc, dictionary)\n",
    "            vectors_2 = map_to_bow(s2_preproc, dictionary)\n",
    "        else:\n",
    "            vectors_1 = map_to_tf_idf(s1_preproc, dictionary, model_tfidf)\n",
    "            vectors_2 = map_to_tf_idf(s2_preproc, dictionary, model_tfidf)\n",
    "\n",
    "        pair_vectors.append(((vectors_1, vectors_2), sim))\n",
    "    return pair_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BOW pairs\n",
    "df_bow_train = bow_pairs(input_pairs, dict_preproc)\n",
    "df_bow_val = bow_pairs(input_pairs_val, dict_preproc)\n",
    "df_bow_test = bow_pairs(input_pairs_test, dict_preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF pairs\n",
    "df_tfidf_train = bow_pairs(input_pairs, dict_preproc,tf = True,model_tfidf = model_tfidf)\n",
    "df_tfidf_val = bow_pairs(input_pairs_val, dict_preproc,tf = True,model_tfidf = model_tfidf)\n",
    "df_tfidf_test = bow_pairs(input_pairs_test, dict_preproc,tf = True,model_tfidf = model_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We erased stopwords in TF-IDF and BOW models. We therefore expect that the differences between TF-IDF and BOW are not that notable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family:Courier New; color:#994C00\">**Word2Vec/GloVe**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"font-family:Courier New; color:#994C00\">**Load Vectors**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will used pretrained catalan Word2Vec Continous Skipgram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_EMBEDDING_FILE = 'C:/Users/Jordi/Desktop/Universitat/PLH/Models/cat_w2vec/model.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the words and their corresponding vectors\n",
    "wv_model = KeyedVectors.load_word2vec_format(WORD_EMBEDDING_FILE, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_tf_idf(sentence_preproc: List[str], dictionary: Dictionary, tf_idf_model: TfidfModel) -> Tuple[List[np.ndarray], List[float]]:\n",
    "    bow = dictionary.doc2bow(sentence_preproc)\n",
    "    tf_idf = tf_idf_model[bow]\n",
    "    vectors, weights = [], []\n",
    "    for word_index, weight in tf_idf:\n",
    "        word = dictionary.get(word_index)\n",
    "        if word in wv_model:\n",
    "            vectors.append(wv_model[word])\n",
    "            weights.append(weight)\n",
    "    return vectors, weights\n",
    "\n",
    "def map_pairs(\n",
    "        sentence_pairs: List[Tuple[str, str, float]],\n",
    "        dictionary: Dictionary = None,\n",
    "        tf_idf_model: TfidfModel = None,\n",
    ") -> List[Tuple[Tuple[np.ndarray, np.ndarray], float]]:\n",
    "    # Mapeo de los pares de oraciones a pares de vectores\n",
    "    pares_vectores = []\n",
    "    for i, (sentence_1, sentence_2, similitud) in enumerate(sentence_pairs):\n",
    "        sentence_1_preproc = preprocess(sentence_1)\n",
    "        sentence_2_preproc = preprocess(sentence_2)\n",
    "        # Si usamos TF-IDF\n",
    "        if tf_idf_model is not None:\n",
    "            # Cálculo del promedio ponderado por TF-IDF de los word embeddings\n",
    "            vectors1, weights1 = map_tf_idf(sentence_1_preproc, dictionary=dictionary, tf_idf_model=tf_idf_model, )\n",
    "            vectors2, weights2 = map_tf_idf(sentence_2_preproc, dictionary=dictionary, tf_idf_model=tf_idf_model, )\n",
    "            vector1 = np.average(vectors1, weights=weights1, axis=0, )\n",
    "            vector2 = np.average(vectors2, weights=weights2, axis=0, )\n",
    "        else:\n",
    "            # Cálculo del promedio de los word embeddings\n",
    "            vectors1 = [wv_model[word] for word in sentence_1_preproc if word in wv_model]\n",
    "            vectors2 = [wv_model[word] for word in sentence_2_preproc if word in wv_model]\n",
    "            vector1 = np.mean(vectors1, axis=0)\n",
    "            vector2 = np.mean(vectors2, axis=0)\n",
    "        # Añadir a la lista\n",
    "        pares_vectores.append(((vector1, vector2), similitud))\n",
    "    return pares_vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF + W2VEC pairs\n",
    "df_w2vec_tf_train = map_pairs(input_pairs,  tf_idf_model=model_tfidf_complete, dictionary= dict_preproc_complete, )\n",
    "df_w2vec_tf_val = map_pairs(input_pairs_val, tf_idf_model=model_tfidf_complete, dictionary= dict_preproc_complete, )\n",
    "df_w2vec_tf_test = map_pairs(input_pairs_test, tf_idf_model=model_tfidf_complete, dictionary= dict_preproc_complete, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Pairs\n",
    "df_w2vec_train = map_pairs(sentence_pairs = input_pairs,dictionary= dict_preproc_complete)\n",
    "df_w2vec_val = map_pairs(sentence_pairs = input_pairs_val,dictionary= dict_preproc_complete)\n",
    "df_w2vec_test = map_pairs(sentence_pairs = input_pairs_test,dictionary= dict_preproc_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family:Courier New; color:#994C00\">**spaCy**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('ca_core_news_md') # Load catalan model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_spacy(sentence_pairs: List[Tuple[str, str, float]], nlp: spacy.language.Language) -> np.ndarray:\n",
    "\n",
    "    pares_vectores = []\n",
    "    #Per cada frase\n",
    "    for s1,s2,sim in sentence_pairs:\n",
    "\n",
    "        vector1 = nlp(s1).vector\n",
    "        vector2 = nlp(s2).vector\n",
    "\n",
    "        #Afegim vector a llista\n",
    "        pares_vectores.append(((vector1, vector2), sim))\n",
    "        \n",
    "    return pares_vectores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPACY DATAFRAMES\n",
    "df_spacy_train = map_to_spacy(input_pairs, nlp)\n",
    "df_spacy_val = map_to_spacy(input_pairs_val, nlp)\n",
    "df_spacy_test = map_to_spacy(input_pairs_test, nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family:Courier New; color:#994C00\">**RoBERTa CLS/Mitjana**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_r = spacy.load('ca_core_news_trf') # Catalan transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_transformer(sentence_pairs: List[Tuple[str, str, float]], nlp: spacy.language.Language,cls:str = True) -> np.ndarray:\n",
    "\n",
    "    pares_vectores = []\n",
    "    #Per cada frase\n",
    "    for s1,s2,sim in sentence_pairs:\n",
    "\n",
    "        #Si volem el vector CLS\n",
    "        \n",
    "        if cls:\n",
    "            vector1 = nlp(s1)._.trf_data.last_hidden_layer_state.data[0]\n",
    "            vector2 = nlp(s2)._.trf_data.last_hidden_layer_state.data[0]\n",
    "\n",
    "        #Si volem la mitjana dels valors de les frases\n",
    "        else:\n",
    "\n",
    "            vectors1 = nlp(s1)._.trf_data.last_hidden_layer_state.data[1:]\n",
    "            vectors2 = nlp(s2)._.trf_data.last_hidden_layer_state.data[1:]\n",
    "\n",
    "            vector1 = np.mean(vectors1, axis=0)\n",
    "            vector2 = np.mean(vectors2, axis=0)\n",
    "\n",
    "        #Afegim vector a llista\n",
    "        pares_vectores.append(((vector1, vector2), sim))\n",
    "        \n",
    "    return pares_vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLS BERT\n",
    "df_BERT_CLS = map_transformer(input_pairs, nlp_r)\n",
    "df_BERT_CLS_val = map_transformer(input_pairs_val, nlp_r)\n",
    "df_BERT_CLS_test = map_transformer(input_pairs_test, nlp_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEAN BERT\n",
    "df_BERT_MEAN = map_transformer(input_pairs, nlp_r,cls = False)\n",
    "df_BERT_MEAN_val = map_transformer(input_pairs_val, nlp_r,cls = False)\n",
    "df_BERT_MEAN_test = map_transformer(input_pairs_test, nlp_r,cls = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As Roberta cased Finetuned returns the probability, we will be showing the results at last, just after the model embedding representation comparison.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-family:Courier New; color:#336666\">**Model creation**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the example delievered to us.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model_better(embedding_size: int = 300, learning_rate: float = 1e-3) -> tf.keras.Model:\n",
    "    # Capa de entrada para los pares de vectores\n",
    "    input_1 = tf.keras.Input(shape=(embedding_size,))\n",
    "    input_2 = tf.keras.Input(shape=(embedding_size,))\n",
    "\n",
    "    # Hidden layer\n",
    "    first_projection = tf.keras.layers.Dense(\n",
    "        embedding_size,\n",
    "        kernel_initializer=tf.keras.initializers.Identity(),\n",
    "        bias_initializer=tf.keras.initializers.Zeros(),\n",
    "    )\n",
    "    projected_1 =  first_projection(input_1)\n",
    "    projected_2 = first_projection(input_2)\n",
    "    \n",
    "    # Compute the cosine distance using a Lambda layer\n",
    "    def normalized_product(x):\n",
    "        x1, x2 = x\n",
    "        x1_normalized = tf.keras.backend.l2_normalize(x1, axis=1)\n",
    "        x2_normalized = tf.keras.backend.l2_normalize(x2, axis=1)\n",
    "        return x1_normalized * x2_normalized\n",
    "\n",
    "    output = tf.keras.layers.Lambda(normalized_product)([projected_1, projected_2])\n",
    "    output = tf.keras.layers.Dropout(0.1)(output)\n",
    "    output = tf.keras.layers.Dense(\n",
    "        16,\n",
    "        activation=\"relu\",\n",
    "    )(output)\n",
    "    output = tf.keras.layers.Dropout(0.2)(output)\n",
    "    output = tf.keras.layers.Dense(\n",
    "        1,\n",
    "        activation=\"sigmoid\",\n",
    "    )(output)\n",
    "    \n",
    "    output = tf.keras.layers.Lambda(lambda x: x * 5)(output)\n",
    "\n",
    "    # Define output\n",
    "    model = tf.keras.Model(inputs=[input_1, input_2], outputs=output)\n",
    "\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training constants\n",
    "batch_size: int = 64\n",
    "num_epochs: int = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=5,          \n",
    "    restore_best_weights=True  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrada vàlida per al model\n",
    "def pair_list_to_x_y(pair_list: List[Tuple[Tuple[np.ndarray, np.ndarray], int]]) -> Tuple[Tuple[np.ndarray, np.ndarray], np.ndarray]:\n",
    "\n",
    "    _x, _y = zip(*pair_list)\n",
    "    _x_1, _x_2 = zip(*_x)\n",
    "    return (np.array(_x_1), np.array(_x_2)), np.array(_y, dtype=np.float32, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-family:Courier New; color:#336666\">**Model evaluation**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns = [\"Pearson_train\",\"Spearman_train\",\"Pearson_val\",\"Spearman_val\"],index = [\"BOW\",\"TF-IDF\",\"W2VEC+TF-IDF\",\"W2VEC+MEAN\",\"SPACY_MD\",\"RoBERTa + CLS\",\"RoBERTa + MEAN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pearson_spearman(x_, y_,model):\n",
    "    # Obtener las predicciones del modelo para los datos de prueba. En este ejemplo vamos a utilizar el corpus de training.\n",
    "    y_pred = model.predict(x_)\n",
    "    print(np.max(y_pred))\n",
    "    # Calcular la correlación de Pearson entre las predicciones y los datos de prueba\n",
    "    pearson, _ = pearsonr(y_pred.flatten(), y_.flatten())\n",
    "    spearman,_ = spearmanr(y_pred.flatten(), y_.flatten())\n",
    "    return pearson, spearman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family:Courier New; color:#994C00\">**BOW**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separació x-y\n",
    "x_train_bow, y_train_bow = pair_list_to_x_y(df_bow_train)\n",
    "x_val_bow, y_val_bow = pair_list_to_x_y(df_bow_val)\n",
    "\n",
    "#Preparar el conjunt\n",
    "\n",
    "train_bow = tf.data.Dataset.from_tensor_slices((x_train_bow, y_train_bow))\n",
    "train_bow = train_bow.shuffle(buffer_size=len(x_train_bow)).batch(batch_size)\n",
    "\n",
    "val__bow = tf.data.Dataset.from_tensor_slices((x_val_bow, y_val_bow))\n",
    "val__bow = val__bow.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:184: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construir y compilar el modelo\n",
    "model_bow = build_and_compile_model_better()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7350 - val_loss: 0.7245\n",
      "Epoch 2/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7256 - val_loss: 0.7210\n",
      "Epoch 3/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7138 - val_loss: 0.7174\n",
      "Epoch 4/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7041 - val_loss: 0.7140\n",
      "Epoch 5/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6900 - val_loss: 0.7087\n",
      "Epoch 6/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6648 - val_loss: 0.7039\n",
      "Epoch 7/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6293 - val_loss: 0.7000\n",
      "Epoch 8/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5795 - val_loss: 0.6996\n",
      "Epoch 9/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5202 - val_loss: 0.7052\n",
      "Epoch 10/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4637 - val_loss: 0.7118\n",
      "Epoch 11/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4193 - val_loss: 0.7180\n",
      "Epoch 12/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3722 - val_loss: 0.7280\n",
      "Epoch 13/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3318 - val_loss: 0.7407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f996d68b90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model_bow.fit(train_bow, epochs=num_epochs, validation_data=val__bow, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "3.1999726\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "3.2412047\n"
     ]
    }
   ],
   "source": [
    "pearson_train_bow, spearman_train_bow = compute_pearson_spearman(x_train_bow, y_train_bow,model_bow)\n",
    "pearson_val_bow, spearman_val_bow = compute_pearson_spearman(x_val_bow, y_val_bow,model_bow)\n",
    "\n",
    "results_df.loc[\"BOW\"] = [pearson_train_bow,spearman_train_bow,pearson_val_bow,spearman_val_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pearson_train</th>\n",
       "      <th>Spearman_train</th>\n",
       "      <th>Pearson_val</th>\n",
       "      <th>Spearman_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BOW</th>\n",
       "      <td>0.617894</td>\n",
       "      <td>0.655386</td>\n",
       "      <td>0.204644</td>\n",
       "      <td>0.212015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF-IDF</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W2VEC+TF-IDF</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W2VEC+MEAN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPACY_MD</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoBERTa + CLS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoBERTa + MEAN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Pearson_train Spearman_train Pearson_val Spearman_val\n",
       "BOW                 0.617894       0.655386    0.204644     0.212015\n",
       "TF-IDF                   NaN            NaN         NaN          NaN\n",
       "W2VEC+TF-IDF             NaN            NaN         NaN          NaN\n",
       "W2VEC+MEAN               NaN            NaN         NaN          NaN\n",
       "SPACY_MD                 NaN            NaN         NaN          NaN\n",
       "RoBERTa + CLS            NaN            NaN         NaN          NaN\n",
       "RoBERTa + MEAN           NaN            NaN         NaN          NaN"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family:Courier New; color:#994C00\">**TF-IDF**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separació x-y\n",
    "x_train_tfidf, y_train_tfidf = pair_list_to_x_y(df_tfidf_train)\n",
    "x_val_tfidf, y_val_tfidf = pair_list_to_x_y(df_tfidf_val)\n",
    "\n",
    "#Preparar el conjunt\n",
    "\n",
    "train_tfidf = tf.data.Dataset.from_tensor_slices((x_train_tfidf, y_train_tfidf))\n",
    "train_tfidf = train_tfidf.shuffle(buffer_size=len(x_train_tfidf)).batch(batch_size)\n",
    "\n",
    "val_tfidf = tf.data.Dataset.from_tensor_slices((x_val_tfidf, y_val_tfidf))\n",
    "val_tfidf = val_tfidf.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir y compilar el modelo\n",
    "model_tfidf = build_and_compile_model_better()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7382 - val_loss: 0.7207\n",
      "Epoch 2/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7235 - val_loss: 0.7181\n",
      "Epoch 3/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7176 - val_loss: 0.7162\n",
      "Epoch 4/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7081 - val_loss: 0.7144\n",
      "Epoch 5/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6908 - val_loss: 0.7106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f99ffbf850>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tfidf.fit(train_tfidf, epochs=num_epochs, validation_data=val_tfidf, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "2.6807377\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "2.686615\n"
     ]
    }
   ],
   "source": [
    "# Avaluació\n",
    "\n",
    "pearson_train_tfidf, spearman_train_tfidf = compute_pearson_spearman(x_train_tfidf, y_train_tfidf,model_tfidf)\n",
    "pearson_val_tfidf, spearman_val_tfidf = compute_pearson_spearman(x_val_tfidf, y_val_tfidf,model_tfidf)\n",
    "\n",
    "results_df.loc[\"TF-IDF\"] = [pearson_train_tfidf,spearman_train_tfidf,pearson_val_tfidf,spearman_val_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pearson_train</th>\n",
       "      <th>Spearman_train</th>\n",
       "      <th>Pearson_val</th>\n",
       "      <th>Spearman_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BOW</th>\n",
       "      <td>0.617894</td>\n",
       "      <td>0.655386</td>\n",
       "      <td>0.204644</td>\n",
       "      <td>0.212015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF-IDF</th>\n",
       "      <td>0.138521</td>\n",
       "      <td>0.170491</td>\n",
       "      <td>0.157639</td>\n",
       "      <td>0.137848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W2VEC+TF-IDF</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W2VEC+MEAN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPACY_MD</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoBERTa + CLS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoBERTa + MEAN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Pearson_train Spearman_train Pearson_val Spearman_val\n",
       "BOW                 0.617894       0.655386    0.204644     0.212015\n",
       "TF-IDF              0.138521       0.170491    0.157639     0.137848\n",
       "W2VEC+TF-IDF             NaN            NaN         NaN          NaN\n",
       "W2VEC+MEAN               NaN            NaN         NaN          NaN\n",
       "SPACY_MD                 NaN            NaN         NaN          NaN\n",
       "RoBERTa + CLS            NaN            NaN         NaN          NaN\n",
       "RoBERTa + MEAN           NaN            NaN         NaN          NaN"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family:Courier New; color:#994C00\">**W2VEC + TF-IDF**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separació x-y\n",
    "x_train_w2vec_tf, y_train_w2vec_tf = pair_list_to_x_y(df_w2vec_tf_train)\n",
    "x_val_w2vec_tf, y_val_w2vec_tf = pair_list_to_x_y(df_w2vec_tf_val)\n",
    "\n",
    "#Preparar el conjunt\n",
    "\n",
    "train_w2vec_tf = tf.data.Dataset.from_tensor_slices((x_train_w2vec_tf, y_train_w2vec_tf))\n",
    "train_w2vec_tf = train_w2vec_tf.shuffle(buffer_size=len(x_train_w2vec_tf)).batch(batch_size)\n",
    "\n",
    "val_w2vec_tf = tf.data.Dataset.from_tensor_slices((x_val_w2vec_tf, y_val_w2vec_tf))\n",
    "val_w2vec_tf = val_w2vec_tf.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir y compilar el modelo\n",
    "model_w2vec_tf = build_and_compile_model_better(embedding_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.7373 - val_loss: 0.7247\n",
      "Epoch 2/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7269 - val_loss: 0.7162\n",
      "Epoch 3/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7113 - val_loss: 0.7099\n",
      "Epoch 4/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6932 - val_loss: 0.7028\n",
      "Epoch 5/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6804 - val_loss: 0.6958\n",
      "Epoch 6/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6626 - val_loss: 0.6875\n",
      "Epoch 7/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6413 - val_loss: 0.6776\n",
      "Epoch 8/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6230 - val_loss: 0.6699\n",
      "Epoch 9/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5934 - val_loss: 0.6617\n",
      "Epoch 10/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5665 - val_loss: 0.6531\n",
      "Epoch 11/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5398 - val_loss: 0.6494\n",
      "Epoch 12/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5127 - val_loss: 0.6490\n",
      "Epoch 13/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4792 - val_loss: 0.6538\n",
      "Epoch 14/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4545 - val_loss: 0.6525\n",
      "Epoch 15/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4356 - val_loss: 0.6532\n",
      "Epoch 16/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3943 - val_loss: 0.6570\n",
      "Epoch 17/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3837 - val_loss: 0.6619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f99ffde490>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2vec_tf.fit(train_w2vec_tf, epochs=num_epochs, validation_data=val_w2vec_tf, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "3.5313864\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step\n",
      "3.3289063\n"
     ]
    }
   ],
   "source": [
    "# Avaluació\n",
    "\n",
    "pearson_train_w2vec_tf, spearman_train_w2vec_tf = compute_pearson_spearman(x_train_w2vec_tf, y_train_w2vec_tf,model_w2vec_tf)\n",
    "pearson_val_w2vec_tf, spearman_val_w2vec_tf = compute_pearson_spearman(x_val_w2vec_tf, y_val_w2vec_tf,model_w2vec_tf)\n",
    "\n",
    "results_df.loc[\"W2VEC+TF-IDF\"] = [pearson_train_w2vec_tf,spearman_train_w2vec_tf,pearson_val_w2vec_tf,spearman_val_w2vec_tf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pearson_train</th>\n",
       "      <th>Spearman_train</th>\n",
       "      <th>Pearson_val</th>\n",
       "      <th>Spearman_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BOW</th>\n",
       "      <td>0.617894</td>\n",
       "      <td>0.655386</td>\n",
       "      <td>0.204644</td>\n",
       "      <td>0.212015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF-IDF</th>\n",
       "      <td>0.138521</td>\n",
       "      <td>0.170491</td>\n",
       "      <td>0.157639</td>\n",
       "      <td>0.137848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W2VEC+TF-IDF</th>\n",
       "      <td>0.676864</td>\n",
       "      <td>0.662533</td>\n",
       "      <td>0.3299</td>\n",
       "      <td>0.34085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W2VEC+MEAN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPACY_MD</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoBERTa + CLS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoBERTa + MEAN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Pearson_train Spearman_train Pearson_val Spearman_val\n",
       "BOW                 0.617894       0.655386    0.204644     0.212015\n",
       "TF-IDF              0.138521       0.170491    0.157639     0.137848\n",
       "W2VEC+TF-IDF        0.676864       0.662533      0.3299      0.34085\n",
       "W2VEC+MEAN               NaN            NaN         NaN          NaN\n",
       "SPACY_MD                 NaN            NaN         NaN          NaN\n",
       "RoBERTa + CLS            NaN            NaN         NaN          NaN\n",
       "RoBERTa + MEAN           NaN            NaN         NaN          NaN"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family:Courier New; color:#994C00\">**W2VEC + MEAN**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separació x-y\n",
    "x_train_w2vec, y_train_w2vec = pair_list_to_x_y(df_w2vec_train)\n",
    "x_val_w2vec, y_val_w2vec = pair_list_to_x_y(df_w2vec_val)\n",
    "\n",
    "#Preparar el conjunt\n",
    "\n",
    "train_w2vec = tf.data.Dataset.from_tensor_slices((x_train_w2vec, y_train_w2vec))\n",
    "train_w2vec = train_w2vec.shuffle(buffer_size=len(x_train_w2vec)).batch(batch_size)\n",
    "\n",
    "val_w2vec = tf.data.Dataset.from_tensor_slices((x_val_w2vec, y_val_w2vec))\n",
    "val_w2vec = val_w2vec.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir y compilar el modelo\n",
    "model_w2vec = build_and_compile_model_better(embedding_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.7322 - val_loss: 0.7200\n",
      "Epoch 2/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7187 - val_loss: 0.7115\n",
      "Epoch 3/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6993 - val_loss: 0.7028\n",
      "Epoch 4/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6810 - val_loss: 0.6948\n",
      "Epoch 5/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6666 - val_loss: 0.6871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f99d665710>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2vec.fit(train_w2vec, epochs=num_epochs, validation_data=val_w2vec, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "2.6370664\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "2.6323435\n"
     ]
    }
   ],
   "source": [
    "# Avaluació\n",
    "\n",
    "pearson_train_w2vec, spearman_train_w2vec = compute_pearson_spearman(x_train_w2vec, y_train_w2vec,model_w2vec)\n",
    "pearson_val_w2vec, spearman_val_w2vec = compute_pearson_spearman(x_val_w2vec, y_val_w2vec,model_w2vec)\n",
    "\n",
    "results_df.loc[\"W2VEC+MEAN\"] = [pearson_train_w2vec,spearman_train_w2vec,pearson_val_w2vec,spearman_val_w2vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pearson_train</th>\n",
       "      <th>Spearman_train</th>\n",
       "      <th>Pearson_val</th>\n",
       "      <th>Spearman_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BOW</th>\n",
       "      <td>0.617894</td>\n",
       "      <td>0.655386</td>\n",
       "      <td>0.204644</td>\n",
       "      <td>0.212015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF-IDF</th>\n",
       "      <td>0.138521</td>\n",
       "      <td>0.170491</td>\n",
       "      <td>0.157639</td>\n",
       "      <td>0.137848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W2VEC+TF-IDF</th>\n",
       "      <td>0.676864</td>\n",
       "      <td>0.662533</td>\n",
       "      <td>0.3299</td>\n",
       "      <td>0.34085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W2VEC+MEAN</th>\n",
       "      <td>0.264724</td>\n",
       "      <td>0.261133</td>\n",
       "      <td>0.161652</td>\n",
       "      <td>0.192895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPACY_MD</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoBERTa + CLS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoBERTa + MEAN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Pearson_train Spearman_train Pearson_val Spearman_val\n",
       "BOW                 0.617894       0.655386    0.204644     0.212015\n",
       "TF-IDF              0.138521       0.170491    0.157639     0.137848\n",
       "W2VEC+TF-IDF        0.676864       0.662533      0.3299      0.34085\n",
       "W2VEC+MEAN          0.264724       0.261133    0.161652     0.192895\n",
       "SPACY_MD                 NaN            NaN         NaN          NaN\n",
       "RoBERTa + CLS            NaN            NaN         NaN          NaN\n",
       "RoBERTa + MEAN           NaN            NaN         NaN          NaN"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family:Courier New; color:#994C00\">**SPACY_MD**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separació x-y\n",
    "x_train_spacy, y_train_spacy = pair_list_to_x_y(df_spacy_train)\n",
    "x_val_spacy, y_val_spacy = pair_list_to_x_y(df_spacy_val)\n",
    "\n",
    "#Preparar el conjunt\n",
    "\n",
    "train_spacy = tf.data.Dataset.from_tensor_slices((x_train_spacy, y_train_spacy))\n",
    "train_spacy = train_spacy.shuffle(buffer_size=len(x_train_spacy)).batch(batch_size)\n",
    "\n",
    "val_spacy = tf.data.Dataset.from_tensor_slices((x_val_spacy, y_val_spacy))\n",
    "val_spacy = val_spacy.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir y compilar el modelo\n",
    "model_spacy = build_and_compile_model_better()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.7326 - val_loss: 0.7149\n",
      "Epoch 2/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7145 - val_loss: 0.7016\n",
      "Epoch 3/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7004 - val_loss: 0.6870\n",
      "Epoch 4/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6730 - val_loss: 0.6776\n",
      "Epoch 5/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6495 - val_loss: 0.6694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f99c3958d0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_spacy.fit(train_spacy, epochs=num_epochs, validation_data=val_spacy, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "2.6531262\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "2.646244\n"
     ]
    }
   ],
   "source": [
    "# Avaluació\n",
    "\n",
    "pearson_train_spacy, spearman_train_spacy = compute_pearson_spearman(x_train_spacy, y_train_spacy,model_spacy)\n",
    "pearson_val_spacy, spearman_val_spacy = compute_pearson_spearman(x_val_spacy, y_val_spacy,model_spacy)\n",
    "\n",
    "results_df.loc[\"SPACY_MD\"] = [pearson_train_spacy,spearman_train_spacy,pearson_val_spacy,spearman_val_spacy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pearson_train</th>\n",
       "      <th>Spearman_train</th>\n",
       "      <th>Pearson_val</th>\n",
       "      <th>Spearman_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BOW</th>\n",
       "      <td>0.617894</td>\n",
       "      <td>0.655386</td>\n",
       "      <td>0.204644</td>\n",
       "      <td>0.212015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF-IDF</th>\n",
       "      <td>0.138521</td>\n",
       "      <td>0.170491</td>\n",
       "      <td>0.157639</td>\n",
       "      <td>0.137848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W2VEC+TF-IDF</th>\n",
       "      <td>0.676864</td>\n",
       "      <td>0.662533</td>\n",
       "      <td>0.3299</td>\n",
       "      <td>0.34085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W2VEC+MEAN</th>\n",
       "      <td>0.264724</td>\n",
       "      <td>0.261133</td>\n",
       "      <td>0.161652</td>\n",
       "      <td>0.192895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPACY_MD</th>\n",
       "      <td>0.251059</td>\n",
       "      <td>0.239841</td>\n",
       "      <td>0.205978</td>\n",
       "      <td>0.163019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoBERTa + CLS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoBERTa + MEAN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Pearson_train Spearman_train Pearson_val Spearman_val\n",
       "BOW                 0.617894       0.655386    0.204644     0.212015\n",
       "TF-IDF              0.138521       0.170491    0.157639     0.137848\n",
       "W2VEC+TF-IDF        0.676864       0.662533      0.3299      0.34085\n",
       "W2VEC+MEAN          0.264724       0.261133    0.161652     0.192895\n",
       "SPACY_MD            0.251059       0.239841    0.205978     0.163019\n",
       "RoBERTa + CLS            NaN            NaN         NaN          NaN\n",
       "RoBERTa + MEAN           NaN            NaN         NaN          NaN"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family:Courier New; color:#994C00\">**RoBERTa + CLS**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separació x-y\n",
    "x_train_bert_cls, y_train_bert_cls = pair_list_to_x_y(df_BERT_CLS)\n",
    "x_val_bert_cls, y_val_bert_cls = pair_list_to_x_y(df_BERT_CLS_val)\n",
    "\n",
    "#Preparar el conjunt\n",
    "\n",
    "train_bert_cls = tf.data.Dataset.from_tensor_slices((x_train_bert_cls, y_train_bert_cls))\n",
    "train_bert_cls = train_bert_cls.shuffle(buffer_size=len(x_train_bert_cls)).batch(batch_size)\n",
    "\n",
    "val_bert_cls = tf.data.Dataset.from_tensor_slices((x_val_bert_cls, y_val_bert_cls))\n",
    "val_bert_cls = val_bert_cls.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir y compilar el modelo\n",
    "model_bert_cls = build_and_compile_model_better(embedding_size=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.7335 - val_loss: 0.7203\n",
      "Epoch 2/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.7231 - val_loss: 0.7133\n",
      "Epoch 3/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7075 - val_loss: 0.7054\n",
      "Epoch 4/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6898 - val_loss: 0.7007\n",
      "Epoch 5/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6705 - val_loss: 0.6976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f996fb2710>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model_bert_cls.fit(train_bert_cls, epochs=num_epochs, validation_data=val_bert_cls, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "2.643705\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "2.6436658\n"
     ]
    }
   ],
   "source": [
    "# Avaluació\n",
    "\n",
    "pearson_train_bert_cls, spearman_train_bert_cls = compute_pearson_spearman(x_train_bert_cls, y_train_bert_cls,model_bert_cls)\n",
    "pearson_val_bert_cls, spearman_val_bert_cls = compute_pearson_spearman(x_val_bert_cls, y_val_bert_cls,model_bert_cls)\n",
    "\n",
    "results_df.loc[\"RoBERTa + CLS\"] = [pearson_train_bert_cls,spearman_train_bert_cls,pearson_val_bert_cls,spearman_val_bert_cls]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family:Courier New; color:#994C00\">**RoBERTa + MEAN**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separació x-y\n",
    "x_train_bert_mean, y_train_bert_mean = pair_list_to_x_y(df_BERT_MEAN)\n",
    "x_val_bert_mean, y_val_bert_mean = pair_list_to_x_y(df_BERT_MEAN_val)\n",
    "\n",
    "#Preparar el conjunt\n",
    "\n",
    "train_bert_mean = tf.data.Dataset.from_tensor_slices((x_train_bert_mean, y_train_bert_mean))\n",
    "train_bert_mean = train_bert_mean.shuffle(buffer_size=len(x_train_bert_mean)).batch(batch_size)\n",
    "\n",
    "val_bert_mean = tf.data.Dataset.from_tensor_slices((x_val_bert_mean, y_val_bert_mean))\n",
    "val_bert_mean = val_bert_mean.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir y compilar el modelo\n",
    "model_bert_mean = build_and_compile_model_better(embedding_size=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.7349 - val_loss: 0.7254\n",
      "Epoch 2/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7280 - val_loss: 0.7193\n",
      "Epoch 3/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7160 - val_loss: 0.7116\n",
      "Epoch 4/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6931 - val_loss: 0.7029\n",
      "Epoch 5/64\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6725 - val_loss: 0.6943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f9a0031dd0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model_bert_mean.fit(train_bert_mean, epochs=num_epochs, validation_data=val_bert_mean, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "2.5859168\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "2.58448\n"
     ]
    }
   ],
   "source": [
    "# Avaluació\n",
    "\n",
    "pearson_train_bert_mean, spearman_train_bert_mean = compute_pearson_spearman(x_train_bert_mean, y_train_bert_mean,model_bert_mean)\n",
    "pearson_val_bert_mean, spearman_val_bert_mean = compute_pearson_spearman(x_val_bert_mean, y_val_bert_mean,model_bert_mean)\n",
    "\n",
    "results_df.loc[\"RoBERTa + MEAN\"] = [pearson_train_bert_mean,spearman_train_bert_mean,pearson_val_bert_mean,spearman_val_bert_mean]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pearson_train</th>\n",
       "      <th>Spearman_train</th>\n",
       "      <th>Pearson_val</th>\n",
       "      <th>Spearman_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BOW</th>\n",
       "      <td>0.617894</td>\n",
       "      <td>0.655386</td>\n",
       "      <td>0.204644</td>\n",
       "      <td>0.212015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF-IDF</th>\n",
       "      <td>0.138521</td>\n",
       "      <td>0.170491</td>\n",
       "      <td>0.157639</td>\n",
       "      <td>0.137848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W2VEC+TF-IDF</th>\n",
       "      <td>0.676864</td>\n",
       "      <td>0.662533</td>\n",
       "      <td>0.3299</td>\n",
       "      <td>0.34085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W2VEC+MEAN</th>\n",
       "      <td>0.264724</td>\n",
       "      <td>0.261133</td>\n",
       "      <td>0.161652</td>\n",
       "      <td>0.192895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPACY_MD</th>\n",
       "      <td>0.251059</td>\n",
       "      <td>0.239841</td>\n",
       "      <td>0.205978</td>\n",
       "      <td>0.163019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoBERTa + CLS</th>\n",
       "      <td>0.221038</td>\n",
       "      <td>0.229657</td>\n",
       "      <td>0.150123</td>\n",
       "      <td>0.157386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoBERTa + MEAN</th>\n",
       "      <td>0.262524</td>\n",
       "      <td>0.242089</td>\n",
       "      <td>0.155967</td>\n",
       "      <td>0.141411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Pearson_train Spearman_train Pearson_val Spearman_val\n",
       "BOW                 0.617894       0.655386    0.204644     0.212015\n",
       "TF-IDF              0.138521       0.170491    0.157639     0.137848\n",
       "W2VEC+TF-IDF        0.676864       0.662533      0.3299      0.34085\n",
       "W2VEC+MEAN          0.264724       0.261133    0.161652     0.192895\n",
       "SPACY_MD            0.251059       0.239841    0.205978     0.163019\n",
       "RoBERTa + CLS       0.221038       0.229657    0.150123     0.157386\n",
       "RoBERTa + MEAN      0.262524       0.242089    0.155967     0.141411"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family:Courier New; color:#994C00\">**RoBERTa finetuned**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get x and y from pairs\n",
    "def get_x_y(pairs):\n",
    "    x = [(a[0],a[1]) for a in pairs]\n",
    "    y = [a[2] for a in pairs]\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# Load model and preprocessing\n",
    "model = 'projecte-aina/roberta-base-ca-v2-cased-sts'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "pipe = pipeline('text-classification', model=model, tokenizer=tokenizer)\n",
    "\n",
    "def prepare(sentence_pairs):\n",
    "    sentence_pairs_prep = []\n",
    "    for s1, s2 in sentence_pairs:\n",
    "        sentence_pairs_prep.append(f\"{tokenizer.cls_token} {s1}{tokenizer.sep_token}{tokenizer.sep_token} {s2}{tokenizer.sep_token}\")\n",
    "    return sentence_pairs_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_finetuned,y_train_finetuned = get_x_y(input_pairs)\n",
    "x_val_finetuned,y_val_finetuned = get_x_y(input_pairs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making predictions\n",
    "predictions_train = pipe(prepare(x_train_finetuned), add_special_tokens=False)\n",
    "predictions_val = pipe(prepare(x_val_finetuned), add_special_tokens=False)\n",
    "\n",
    "# convert back to scores to the original 0 and 5 interval\n",
    "for prediction in predictions_train:\n",
    "    prediction['score'] = scipy.special.logit(prediction['score'])\n",
    "for prediction in predictions_val:\n",
    "    prediction['score'] = scipy.special.logit(prediction['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_spearman(y_true, y_pred):\n",
    "    # Calcular la correlación de Pearson entre las predicciones y los datos de prueba\n",
    "    pearson, _ = pearsonr(y_pred.flatten(), y_true.flatten())\n",
    "    spearman,_ = spearmanr(y_pred.flatten(), y_true.flatten())\n",
    "    return pearson, spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Pearson and Spearman correlation\n",
    "\n",
    "pearson_train_finetuned, spearman_train_finetuned = pearson_spearman(np.array(y_train_finetuned), np.array([p['score'] for p in predictions_train]))\n",
    "pearson_val_finetuned, spearman_val_finetuned = pearson_spearman(np.array(y_val_finetuned), np.array([p['score'] for p in predictions_val]))\n",
    "\n",
    "results_df.loc[\"RoBERTa + Finetuned\"] = [pearson_train_finetuned,spearman_train_finetuned,pearson_val_finetuned,spearman_val_finetuned]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pearson_train</th>\n",
       "      <th>Spearman_train</th>\n",
       "      <th>Pearson_val</th>\n",
       "      <th>Spearman_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BOW</th>\n",
       "      <td>0.617894</td>\n",
       "      <td>0.655386</td>\n",
       "      <td>0.204644</td>\n",
       "      <td>0.212015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF-IDF</th>\n",
       "      <td>0.138521</td>\n",
       "      <td>0.170491</td>\n",
       "      <td>0.157639</td>\n",
       "      <td>0.137848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W2VEC+TF-IDF</th>\n",
       "      <td>0.676864</td>\n",
       "      <td>0.662533</td>\n",
       "      <td>0.3299</td>\n",
       "      <td>0.34085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W2VEC+MEAN</th>\n",
       "      <td>0.264724</td>\n",
       "      <td>0.261133</td>\n",
       "      <td>0.161652</td>\n",
       "      <td>0.192895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPACY_MD</th>\n",
       "      <td>0.251059</td>\n",
       "      <td>0.239841</td>\n",
       "      <td>0.205978</td>\n",
       "      <td>0.163019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoBERTa + CLS</th>\n",
       "      <td>0.221038</td>\n",
       "      <td>0.229657</td>\n",
       "      <td>0.150123</td>\n",
       "      <td>0.157386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoBERTa + MEAN</th>\n",
       "      <td>0.262524</td>\n",
       "      <td>0.242089</td>\n",
       "      <td>0.155967</td>\n",
       "      <td>0.141411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoBERTa + Finetuned</th>\n",
       "      <td>0.947429</td>\n",
       "      <td>0.961433</td>\n",
       "      <td>0.75226</td>\n",
       "      <td>0.731941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Pearson_train Spearman_train Pearson_val Spearman_val\n",
       "BOW                      0.617894       0.655386    0.204644     0.212015\n",
       "TF-IDF                   0.138521       0.170491    0.157639     0.137848\n",
       "W2VEC+TF-IDF             0.676864       0.662533      0.3299      0.34085\n",
       "W2VEC+MEAN               0.264724       0.261133    0.161652     0.192895\n",
       "SPACY_MD                 0.251059       0.239841    0.205978     0.163019\n",
       "RoBERTa + CLS            0.221038       0.229657    0.150123     0.157386\n",
       "RoBERTa + MEAN           0.262524       0.242089    0.155967     0.141411\n",
       "RoBERTa + Finetuned      0.947429       0.961433     0.75226     0.731941"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jordi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\spatial\\distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "# Make another table, but the predictions are made with cosine distance\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "results_cosine = pd.DataFrame(columns = [\"Pearson_train\",\"Spearman_train\",\"Pearson_val\",\"Spearman_val\"],index = [\"BOW\",\"TF-IDF\",\"W2VEC+TF-IDF\",\"W2VEC+MEAN\",\"SPACY_MD\",\"RoBERTa + CLS\",\"RoBERTa + MEAN\",\"RoBERTa + Finetuned\"]) \n",
    "\n",
    "# Baseline\n",
    "def compute_pearson_baseline(x_, y_):\n",
    "    y_pred_baseline = []\n",
    "    for v1, v2 in zip(*x_):\n",
    "        d = 1.0 - scipy.spatial.distance.cosine(v1, v2)\n",
    "        y_pred_baseline.append(d)\n",
    "    # Calcular la correlación de Pearson entre las predicciones y los datos de prueba\n",
    "    pearson, _ = pearsonr(y_pred_baseline, y_.flatten()*5)\n",
    "    spearman,_ = spearmanr(y_pred_baseline, y_.flatten()*5)\n",
    "    return pearson,spearman\n",
    "\n",
    "pearson_train_bow,spearman_train_bow = compute_pearson_baseline(x_train_bow, y_train_bow)\n",
    "pearson_val_bow,spearman_val_bow = compute_pearson_baseline(x_val_bow, y_val_bow)\n",
    "\n",
    "results_cosine.loc[\"BOW\"] = [pearson_train_bow,spearman_train_bow,pearson_val_bow,spearman_val_bow]\n",
    "\n",
    "\n",
    "# TF-IDF\n",
    "pearson_train_tfidf,sperman_train_tfidf = compute_pearson_baseline(x_train_tfidf, y_train_tfidf)\n",
    "pearson_val_tfidf,sperman_val_tfidf = compute_pearson_baseline(x_val_tfidf, y_val_tfidf)\n",
    "\n",
    "results_cosine.loc[\"TF-IDF\"] = [pearson_train_tfidf,sperman_train_tfidf,pearson_val_tfidf,sperman_val_tfidf]\n",
    "\n",
    "\n",
    "# W2VEC + TF-IDF\n",
    "\n",
    "pearson_train_w2vec_tf,sperman_train_w2vec_tf = compute_pearson_baseline(x_train_w2vec_tf, y_train_w2vec_tf)\n",
    "pearson_val_w2vec_tf,sperman_val_w2vec_tf = compute_pearson_baseline(x_val_w2vec_tf, y_val_w2vec_tf)\n",
    "\n",
    "results_cosine.loc[\"W2VEC+TF-IDF\"] = [pearson_train_w2vec_tf,sperman_train_w2vec_tf,pearson_val_w2vec_tf,sperman_val_w2vec_tf]\n",
    "# W2VEC + MEAN\n",
    "\n",
    "pearson_train_w2vec,sperman_train_w2vec = compute_pearson_baseline(x_train_w2vec, y_train_w2vec)\n",
    "pearson_val_w2vec,sperman_val_w2vec = compute_pearson_baseline(x_val_w2vec, y_val_w2vec)\n",
    "\n",
    "results_cosine.loc[\"W2VEC+MEAN\"] = [pearson_train_w2vec,sperman_train_w2vec,pearson_val_w2vec,sperman_val_w2vec]\n",
    "\n",
    "# SPACY\n",
    "\n",
    "pearson_train_spacy,sperman_train_spacy = compute_pearson_baseline(x_train_spacy, y_train_spacy)\n",
    "pearson_val_spacy,sperman_val_spacy = compute_pearson_baseline(x_val_spacy, y_val_spacy)\n",
    "\n",
    "results_cosine.loc[\"SPACY_MD\"] = [pearson_train_spacy,sperman_train_spacy,pearson_val_spacy,sperman_val_spacy]\n",
    "\n",
    "\n",
    "# RoBERTa + CLS\n",
    "\n",
    "pearson_train_bert_cls,sperman_train_bert_cls = compute_pearson_baseline(x_train_bert_cls, y_train_bert_cls)\n",
    "pearson_val_bert_cls,sperman_val_bert_cls = compute_pearson_baseline(x_val_bert_cls, y_val_bert_cls)\n",
    "\n",
    "results_cosine.loc[\"RoBERTa + CLS\"] = [pearson_train_bert_cls,sperman_train_bert_cls,pearson_val_bert_cls,sperman_val_bert_cls]\n",
    "\n",
    "# RoBERTa + MEAN\n",
    "\n",
    "pearson_train_bert_mean,sperman_train_bert_mean = compute_pearson_baseline(x_train_bert_mean, y_train_bert_mean)\n",
    "pearson_val_bert_mean,sperman_val_bert_mean = compute_pearson_baseline(x_val_bert_mean, y_val_bert_mean)\n",
    "\n",
    "results_cosine.loc[\"RoBERTa + MEAN\"] = [pearson_train_bert_mean,sperman_train_bert_mean,pearson_val_bert_mean,sperman_val_bert_mean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cosine.loc[\"RoBERTa + Finetuned\"] = [pearson_train_finetuned,spearman_train_finetuned,pearson_val_finetuned,spearman_val_finetuned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pearson_train</th>\n",
       "      <th>Spearman_train</th>\n",
       "      <th>Pearson_val</th>\n",
       "      <th>Spearman_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RoBERTa + Finetuned</th>\n",
       "      <td>0.947429</td>\n",
       "      <td>0.961433</td>\n",
       "      <td>0.75226</td>\n",
       "      <td>0.731941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W2VEC+TF-IDF</th>\n",
       "      <td>0.427605</td>\n",
       "      <td>0.469647</td>\n",
       "      <td>0.45547</td>\n",
       "      <td>0.460746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W2VEC+MEAN</th>\n",
       "      <td>0.42764</td>\n",
       "      <td>0.47288</td>\n",
       "      <td>0.426903</td>\n",
       "      <td>0.438519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoBERTa + MEAN</th>\n",
       "      <td>0.366229</td>\n",
       "      <td>0.38737</td>\n",
       "      <td>0.304729</td>\n",
       "      <td>0.305552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF-IDF</th>\n",
       "      <td>0.220896</td>\n",
       "      <td>0.236627</td>\n",
       "      <td>0.215571</td>\n",
       "      <td>0.231584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW</th>\n",
       "      <td>0.22873</td>\n",
       "      <td>0.243772</td>\n",
       "      <td>0.210217</td>\n",
       "      <td>0.22536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPACY_MD</th>\n",
       "      <td>0.236751</td>\n",
       "      <td>0.350948</td>\n",
       "      <td>0.194279</td>\n",
       "      <td>0.283975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoBERTa + CLS</th>\n",
       "      <td>0.144417</td>\n",
       "      <td>0.260255</td>\n",
       "      <td>0.094534</td>\n",
       "      <td>0.200044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Pearson_train Spearman_train Pearson_val Spearman_val\n",
       "RoBERTa + Finetuned      0.947429       0.961433     0.75226     0.731941\n",
       "W2VEC+TF-IDF             0.427605       0.469647     0.45547     0.460746\n",
       "W2VEC+MEAN                0.42764        0.47288    0.426903     0.438519\n",
       "RoBERTa + MEAN           0.366229        0.38737    0.304729     0.305552\n",
       "TF-IDF                   0.220896       0.236627    0.215571     0.231584\n",
       "BOW                       0.22873       0.243772    0.210217      0.22536\n",
       "SPACY_MD                 0.236751       0.350948    0.194279     0.283975\n",
       "RoBERTa + CLS            0.144417       0.260255    0.094534     0.200044"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cosine.sort_values(by = \"Pearson_val\",ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pearson_train</th>\n",
       "      <th>Spearman_train</th>\n",
       "      <th>Pearson_val</th>\n",
       "      <th>Spearman_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RoBERTa + Finetuned</th>\n",
       "      <td>0.947429</td>\n",
       "      <td>0.961433</td>\n",
       "      <td>0.75226</td>\n",
       "      <td>0.731941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W2VEC+TF-IDF</th>\n",
       "      <td>0.676864</td>\n",
       "      <td>0.662533</td>\n",
       "      <td>0.3299</td>\n",
       "      <td>0.34085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPACY_MD</th>\n",
       "      <td>0.251059</td>\n",
       "      <td>0.239841</td>\n",
       "      <td>0.205978</td>\n",
       "      <td>0.163019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW</th>\n",
       "      <td>0.617894</td>\n",
       "      <td>0.655386</td>\n",
       "      <td>0.204644</td>\n",
       "      <td>0.212015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W2VEC+MEAN</th>\n",
       "      <td>0.264724</td>\n",
       "      <td>0.261133</td>\n",
       "      <td>0.161652</td>\n",
       "      <td>0.192895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF-IDF</th>\n",
       "      <td>0.138521</td>\n",
       "      <td>0.170491</td>\n",
       "      <td>0.157639</td>\n",
       "      <td>0.137848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoBERTa + MEAN</th>\n",
       "      <td>0.262524</td>\n",
       "      <td>0.242089</td>\n",
       "      <td>0.155967</td>\n",
       "      <td>0.141411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoBERTa + CLS</th>\n",
       "      <td>0.221038</td>\n",
       "      <td>0.229657</td>\n",
       "      <td>0.150123</td>\n",
       "      <td>0.157386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Pearson_train Spearman_train Pearson_val Spearman_val\n",
       "RoBERTa + Finetuned      0.947429       0.961433     0.75226     0.731941\n",
       "W2VEC+TF-IDF             0.676864       0.662533      0.3299      0.34085\n",
       "SPACY_MD                 0.251059       0.239841    0.205978     0.163019\n",
       "BOW                      0.617894       0.655386    0.204644     0.212015\n",
       "W2VEC+MEAN               0.264724       0.261133    0.161652     0.192895\n",
       "TF-IDF                   0.138521       0.170491    0.157639     0.137848\n",
       "RoBERTa + MEAN           0.262524       0.242089    0.155967     0.141411\n",
       "RoBERTa + CLS            0.221038       0.229657    0.150123     0.157386"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(by = \"Pearson_val\",ascending = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
